{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data and imputation\n",
    "In this notebook, we conduct a simple experiment to highlight advantages\n",
    "and disadvantages of methods for data imputation.\n",
    "We will benchmark mean / mode / median / constant imputation as well as\n",
    "a k-NN-based hot-deck imputation and MICE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Sandbox for notebook\"\"\"\n",
    "# base imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "# exploratory data analysis\n",
    "import missingno, pandas_profiling\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# datasets/training/imputation\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# autoML\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# import impyute, fancyimpute, autoimpute, missingpy, datawig\n",
    "from fancyimpute import KNN\n",
    "# from datawig import SimpleImputer as DWSimpleImputer\n",
    "\n",
    "# progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "# visualisation\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# project base path\n",
    "try:\n",
    "    # inside try to be able to easily run stuff on ipython as well\n",
    "    BASE_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), \"..\")\n",
    "except NameError:\n",
    "    BASE_DIR = \"..\"\n",
    "\n",
    "# plot styling\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"darkgrid\", {\"legend.frameon\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Utility functions for loading different data sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(dataset=\"breast_cancer\"):\n",
    "    \n",
    "    data_dict = {\"iris\": lambda: datasets.load_iris(),\n",
    "                 \"diabetes\": lambda: datasets.load_diabetes(),\n",
    "                 \"digits\": lambda: datasets.load_digits(),\n",
    "                 \"breast_cancer\": lambda: datasets.load_breast_cancer()}\n",
    "\n",
    "    data = data_dict[dataset]()\n",
    "    df = pd.DataFrame(data.data)\n",
    "    if \"feature_names\" in data:\n",
    "        df.columns = data.feature_names\n",
    "\n",
    "    df[\"target\"] = data.target\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "\n",
    "def load_wine():\n",
    "    df = pd.read_csv(os.path.join(BASE_DIR, \"data\", \"winequality-white.csv\"), sep=\";\")\n",
    "    # df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=\";\")\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "def load_census():\n",
    "\n",
    "    CAT = \"category\"\n",
    "    CONT = np.float32\n",
    "\n",
    "    col_names = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education-num\",\n",
    "        \"marital\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\",\n",
    "        \"native-country\",\n",
    "        \">50k\",\n",
    "    ]\n",
    "\n",
    "    dtypes = [\n",
    "        np.int16,\n",
    "        CAT,\n",
    "        CONT,\n",
    "        CAT,\n",
    "        CONT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CONT,\n",
    "        CONT,\n",
    "        CONT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "    ]\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(BASE_DIR, \"data\", \"adult.data\"),\n",
    "        # \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        sep=\",\",\n",
    "        names=col_names,\n",
    "        dtype={k: v for (k, v) in zip(col_names, dtypes)},\n",
    "    )\n",
    "\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for deleting points - both MCAR and MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# introduce missingness - missing completely at random\n",
    "def delete_datapoints(X, columns=None, frac=0.1, missingness=\"mcar\"):\n",
    "    _X = X.copy(deep=True)\n",
    "\n",
    "    if columns is None:\n",
    "        columns = _X.columns\n",
    "\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "\n",
    "    if missingness == \"mcar\":\n",
    "      for col in columns:\n",
    "        nan_idx = _X.sample(frac=frac).index\n",
    "        _X.loc[nan_idx, col] = np.NaN\n",
    "    else:\n",
    "      # set different fractions of missing data depending on the median of the response variable\n",
    "      for col in columns:\n",
    "          nan_idx_1 = _X[y >= np.nanmedian(y)].sample(frac=max(frac - 0.15, 0)).index\n",
    "          nan_idx_2 = _X[y < np.nanmedian(y)].sample(frac=min(frac + 0.15, 1)).index\n",
    "          for indices in [nan_idx_1, nan_idx_2]:\n",
    "              _X.loc[indices, col] = np.NaN\n",
    "\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Function for data imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def impute_data(X, columns=None, strategy=\"mean\", **strategy_kwargs):\n",
    "    _X = X.copy(deep=True)\n",
    "\n",
    "    # complete case is not really an imputation strategy...\n",
    "    if strategy == \"complete_case\":\n",
    "        return _X.dropna()\n",
    "\n",
    "    strategy_dict = {\n",
    "        # use lambda to avoid premature initialisation\n",
    "        \"mean\": lambda: SimpleImputer(missing_values=np.NaN, strategy=\"mean\"),\n",
    "        \"median\": lambda: SimpleImputer(missing_values=np.NaN, strategy=\"median\"),\n",
    "        \"most_frequent\": lambda: SimpleImputer(\n",
    "            missing_values=np.NaN, strategy=\"most_frequent\"\n",
    "        ),\n",
    "        \"zero\": lambda: SimpleImputer(\n",
    "            missing_values=np.NaN, strategy=\"constant\", fill_value=0\n",
    "        ),\n",
    "        \"hot-deck\": lambda: None,\n",
    "        \"knn\": lambda: KNN(**strategy_kwargs),\n",
    "        \"mice\": lambda: IterativeImputer(\n",
    "            max_iter=10, sample_posterior=True, **strategy_kwargs\n",
    "        ),\n",
    "        # \"datawig\": lambda: DWSimpleImputer\n",
    "    }\n",
    "\n",
    "    if columns is None:\n",
    "        columns = _X.columns\n",
    "\n",
    "    imputer = strategy_dict[strategy]()\n",
    "\n",
    "    if strategy == \"datawig\":\n",
    "        _X = imputer.complete(_X)\n",
    "    else:\n",
    "        _X.loc[:, columns] = imputer.fit_transform(_X.loc[:, columns])\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Benchmarking experiment code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=None,\n",
    "    metric=None,\n",
    "    reps=3,\n",
    "    missing_fracs=None,\n",
    "    impute_params=None,\n",
    "    missingness=\"mcar\",\n",
    "):\n",
    "\n",
    "    if missing_fracs is None:\n",
    "        missing_fracs = np.linspace(0.0, 0.9, 5)\n",
    "\n",
    "    if impute_params is None:\n",
    "        impute_params = [\n",
    "            (\"complete_case\", {}),\n",
    "            (\"mean\", {}),\n",
    "            (\"median\", {}),\n",
    "            (\"most_frequent\", {}),\n",
    "            (\"zero\", {}),\n",
    "            (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "            (\"mice\", {}),\n",
    "            # (\"datawig\", {})\n",
    "        ]\n",
    "\n",
    "    results = {\"exp_rep\": [], \"missing_frac\": [], \"strategy\": [], \"metric_score\": []}\n",
    "\n",
    "    # print(\"Split into train and validation set\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "    # print(\"Evaluating different imputation methods w.r.t. model accuracy\")\n",
    "\n",
    "    for rep in range(reps):\n",
    "        # print(\"\\n\\n========== Experiment instance %s ==========\" % rep)\n",
    "        for missing_frac in tqdm(missing_fracs):\n",
    "            # print(\n",
    "            #     \"\\n========== Missing percentage %s%% ==========\"\n",
    "            #     % int(missing_frac * 100)\n",
    "            # )\n",
    "            # print(\"Introducing %s missingness\" %(missingness))\n",
    "            X_train_miss = delete_datapoints(X_train, frac=missing_frac, missingness=missingness)\n",
    "\n",
    "            for (impute_strategy, impute_param) in impute_params:\n",
    "                # print(\"========== Imputation strategy %s ==========\" % impute_strategy)\n",
    "                try:\n",
    "                    X_train_imputed = impute_data(\n",
    "                        X_train_miss, strategy=impute_strategy, **impute_param\n",
    "                    )\n",
    "                    y_train_imputed = y_train.loc[X_train_imputed.index]\n",
    "\n",
    "                    # print(\"Retrain model on imputed data\")\n",
    "                    model.fit(X_train_imputed, y_train_imputed)\n",
    "                    # make use of metric\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    metric_score = metric(y_test, y_pred)\n",
    "                except ValueError as e:\n",
    "                    # print(\n",
    "                    #     \"Could not train model or compute accuracy. Continue to next training instance.\"\n",
    "                    # )\n",
    "                    # print(e)\n",
    "                    continue\n",
    "                # print(\"Metric score: %s\" % metric_score)\n",
    "\n",
    "                results[\"exp_rep\"].append(rep)\n",
    "                results[\"missing_frac\"].append(missing_frac)\n",
    "                results[\"strategy\"].append(impute_strategy)\n",
    "                results[\"metric_score\"].append(metric_score)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility function for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%  \n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_col_vs_metric_score(\n",
    "    results_df,\n",
    "    feature_col=\"missing_frac\",\n",
    "    metric_score=\"metric_score\",\n",
    "    group_col=\"strategy\",\n",
    "):\n",
    "    \"\"\"\n",
    "    How does each model perform based on a single feature (averaged across other relevant features) wrt a metric score\n",
    "    :param group_col:\n",
    "    :param results_df:\n",
    "    :param feature_col:\n",
    "    :param metric_score:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return sns.lineplot(\n",
    "        x=feature_col,\n",
    "        y=metric_score,\n",
    "        hue=group_col,\n",
    "        style=group_col,\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "        data=results_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Running first experiment on wine dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Design matrix\n",
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  \n",
      "0      8.8  \n",
      "1      9.5  \n",
      "2     10.1  \n",
      "3      9.9  \n",
      "4      9.9  \n",
      "\n",
      "Target\n",
      "0    6\n",
      "1    6\n",
      "2    6\n",
      "3    6\n",
      "4    6\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X, y = load_wine()\n",
    "print(\"Design matrix\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce1ee1d670441c7b0dd3bad72ded7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "metric = metrics.mean_squared_error\n",
    "missing_fracs = np.linspace(0.0, 0.9, 5)\n",
    "\n",
    "wine_results_mcar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    missingness=\"mcar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ce6cbd029840cabaa66ab15af2febf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "metric = metrics.mean_squared_error\n",
    "missing_fracs = np.linspace(0.0, 0.9, 5)\n",
    "\n",
    "wine_results_mar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    missingness=\"mar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(wine_results_mcar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(wine_results_mar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "Dj3Ha2OaZaD-",
    "outputId": "c1faf603-cd76-404b-a70d-372f7bc52ab5"
   },
   "outputs": [],
   "source": [
    "X, y = load_data(\"breast_cancer\")\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=40)\n",
    "metric = metrics.accuracy_score\n",
    "missing_fracs = np.linspace(0.0, 0.9, 10)\n",
    "\n",
    "breast_cancer_results_mcar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    missingness=\"mcar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(breast_cancer_results_mcar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_census()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "metric = metrics.accuracy_score\n",
    "missing_fracs = np.linspace(0.0, 0.9, 5)\n",
    "\n",
    "census_results_mcar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    missingness=\"mcar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(census_results_mcar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
