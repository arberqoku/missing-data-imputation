{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMd7ve-iZaCu"
   },
   "source": [
    "## Missing data and imputation\n",
    "In this notebook, we conduct a simple experiment to highlight advantages\n",
    "and disadvantages of methods for data imputation.\n",
    "We will benchmark mean / mode / median / constant imputation as well as\n",
    "a k-NN-based hot-deck imputation and MICE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "EcuiTrZ7ZaC3",
    "outputId": "1a3b172c-966f-4aaf-a12b-4b34b7117e40",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Sandbox for notebook\"\"\"\n",
    "# base imports\n",
    "import os\n",
    "import time\n",
    "\n",
    "# exploratory data analysis\n",
    "# import missingno, pandas_profiling\n",
    "\n",
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# datasets/training/imputation\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# autoML\n",
    "# import h2o\n",
    "# from h2o.automl import H2OAutoML\n",
    "\n",
    "# imputation\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# import impyute, fancyimpute, autoimpute, missingpy, datawig\n",
    "from fancyimpute import KNN\n",
    "from missingpy import MissForest\n",
    "# from datawig import SimpleImputer as DWSimpleImputer\n",
    "\n",
    "# progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "# visualisation\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFklBMOaZaDA"
   },
   "source": [
    "Some settings + seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdX9m85XZaDD",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# project base path\n",
    "try:\n",
    "    # inside try to be able to easily run stuff on ipython as well\n",
    "    BASE_DIR = os.path.join(os.path.abspath(os.path.dirname(__file__)), \"..\")\n",
    "except NameError:\n",
    "    BASE_DIR = \"..\"\n",
    "\n",
    "# plot styling\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"darkgrid\", {\"legend.frameon\": True})\n",
    "\n",
    "# set global seed for reproducible experiments\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jbHiCSQBZaDK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Utility functions for loading different data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GlbQi2lZaDM",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def standardise(X):\n",
    "    return pd.DataFrame(data=StandardScaler().fit_transform(X), columns=X.columns)\n",
    "\n",
    "def load_data(dataset=\"breast_cancer\"):\n",
    "    \n",
    "    data_dict = {\"iris\": lambda: datasets.load_iris(),\n",
    "                 \"diabetes\": lambda: datasets.load_diabetes(),\n",
    "                 \"digits\": lambda: datasets.load_digits(),\n",
    "                 \"breast_cancer\": lambda: datasets.load_breast_cancer()}\n",
    "\n",
    "    data = data_dict[dataset]()\n",
    "    df = pd.DataFrame(data.data)\n",
    "    if \"feature_names\" in data:\n",
    "        df.columns = data.feature_names\n",
    "\n",
    "    df[\"target\"] = data.target\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "\n",
    "def load_wine():\n",
    "    df = pd.read_csv(os.path.join(BASE_DIR, \"data\", \"winequality-white.csv\"), sep=\";\")\n",
    "    # df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\", sep=\";\")\n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]\n",
    "\n",
    "def load_census():\n",
    "\n",
    "    CAT = \"category\"\n",
    "    CONT = np.float32\n",
    "\n",
    "    col_names = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education_num\",\n",
    "        \"marital\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital_gain\",\n",
    "        \"capital_loss\",\n",
    "        \"hours_per_week\",\n",
    "        \"native_country\",\n",
    "        \">50k\",\n",
    "    ]\n",
    "\n",
    "    dtypes = [\n",
    "        np.int16,\n",
    "        CAT,\n",
    "        CONT,\n",
    "        CAT,\n",
    "        CONT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "        CONT,\n",
    "        CONT,\n",
    "        CONT,\n",
    "        CAT,\n",
    "        CAT,\n",
    "    ]\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(BASE_DIR, \"data\", \"adult.data\"),\n",
    "        # \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "        sep=\",\",\n",
    "        names=col_names,\n",
    "        dtype={k: v for (k, v) in zip(col_names, dtypes)},\n",
    "    )\n",
    "    \n",
    "    return df.iloc[:, :-1], df.iloc[:, -1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXDAe-0DZaDR"
   },
   "source": [
    "Methods for deleting points - both MCAR and MAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1XCqBnVZaDV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# introduce missingness - missing completely at random\n",
    "def delete_datapoints(X, y, columns=None, frac=0.1, missingness=\"mcar\"):\n",
    "    \n",
    "    _X = X.copy(deep=True)\n",
    "    _y = y.copy(deep=True)\n",
    "    \n",
    "    if frac == 0:\n",
    "        return _X\n",
    "    \n",
    "    if columns is None:\n",
    "        columns = _X.columns\n",
    "\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]    \n",
    "\n",
    "    if missingness == \"mcar\":\n",
    "        for col in columns:\n",
    "            nan_idx = _X.sample(frac=frac).index\n",
    "            _X.loc[nan_idx, col] = np.NaN\n",
    "    else:\n",
    "        # set different fractions of missing data depending on the median of the response variable\n",
    "        # _X.index = _y.index\n",
    "        for col in columns:\n",
    "            nan_idx_1 = _X[y >= np.nanmedian(y)].sample(frac=max(frac - 0.15, 0)).index.to_list()\n",
    "            nan_idx_2 = _X[y < np.nanmedian(y)].sample(frac=min(frac + 0.15, 1)).index.to_list()\n",
    "            indices = nan_idx_1 + nan_idx_2\n",
    "            _X.loc[indices, col] = np.NaN\n",
    "\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLVpiMvJZaDa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Function for data imputation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itCXAY75ZaDb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def impute_data(X, columns=None, strategy=\"mean\", **strategy_kwargs):\n",
    "    _X = X.copy(deep=True)\n",
    "    \n",
    "    # early return if none missing to avoid warnings \n",
    "    if not _X.isna().any(axis=None):\n",
    "        return _X\n",
    "\n",
    "    # complete case is not really an imputation strategy...\n",
    "    if strategy == \"complete_case\":\n",
    "        return _X.dropna()\n",
    "    \n",
    "    cat_vars = strategy_kwargs.pop(\"cat_vars\", None)\n",
    "    estimator = strategy_kwargs.pop(\"estimator\", None)\n",
    "\n",
    "    strategy_dict = {\n",
    "        # use lambda to avoid premature initialisation\n",
    "        \"mean\": lambda: SimpleImputer(missing_values=np.NaN, strategy=\"mean\"),\n",
    "        \"median\": lambda: SimpleImputer(missing_values=np.NaN, strategy=\"median\"),\n",
    "        \"most_frequent\": lambda: SimpleImputer(\n",
    "            missing_values=np.NaN, strategy=\"most_frequent\"\n",
    "        ),\n",
    "        \"zero\": lambda: SimpleImputer(\n",
    "            missing_values=np.NaN, strategy=\"constant\", fill_value=0\n",
    "        ),\n",
    "        \"knn\": lambda: KNN(**strategy_kwargs),\n",
    "        \"mice\": lambda: IterativeImputer(\n",
    "            estimator=estimator,\n",
    "            max_iter=10, \n",
    "            sample_posterior=estimator is None, \n",
    "            **strategy_kwargs\n",
    "        ),\n",
    "        \"miss-forest\": lambda: MissForest(max_iter=10, **strategy_kwargs),\n",
    "        # \"datawig\": lambda: DWSimpleImputer\n",
    "    }\n",
    "\n",
    "    if columns is None:\n",
    "        columns = _X.columns\n",
    "\n",
    "    imputer = strategy_dict[strategy]()\n",
    "\n",
    "    if strategy == \"datawig\":\n",
    "        _X = imputer.complete(_X)\n",
    "    elif strategy == \"miss-forest\":\n",
    "        imputer.fit(_X.loc[:, columns], cat_vars=cat_vars)\n",
    "        _X.loc[:, columns] = imputer.transform(_X)\n",
    "    else:\n",
    "        _X.loc[:, columns] = imputer.fit_transform(_X.loc[:, columns])\n",
    "    return _X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wLI4ppKZaDg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Benchmarking experiment code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-f6v1NY5ZaDj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=None,\n",
    "    metric=None,\n",
    "    reps=3,\n",
    "    missing_fracs=None,\n",
    "    impute_params=None,\n",
    "    missingness=\"mcar\",\n",
    "):\n",
    "\n",
    "    if missing_fracs is None:\n",
    "        missing_fracs = np.linspace(0.0, 0.9, 5)\n",
    "\n",
    "    if impute_params is None:\n",
    "        impute_params = [\n",
    "            (\"complete_case\", {}),\n",
    "            (\"mean\", {}),\n",
    "            (\"median\", {}),\n",
    "            (\"most_frequent\", {}),\n",
    "            (\"zero\", {}),\n",
    "            (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "            (\"mice\", {}),\n",
    "            # (\"miss-forest\", {\"n_estimators\": 100}),\n",
    "            # (\"datawig\", {})\n",
    "        ]\n",
    "\n",
    "    results = {\"exp_rep\": [], \"missing_frac\": [], \"strategy\": [], \"metric_score\": []}\n",
    "\n",
    "    # print(\"Split into train and validation set\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "    # print(\"Evaluating different imputation methods w.r.t. model accuracy\")\n",
    "\n",
    "    for rep in range(reps):\n",
    "        # print(\"\\n\\n========== Experiment instance %s ==========\" % rep)\n",
    "        for missing_frac in tqdm(missing_fracs):\n",
    "            # print(\n",
    "            #     \"\\n========== Missing percentage %s%% ==========\"\n",
    "            #     % int(missing_frac * 100)\n",
    "            # )\n",
    "            # print(\"Introducing %s missingness\" %(missingness))\n",
    "            X_train_miss = delete_datapoints(X_train, y_train, frac=missing_frac, missingness=missingness)\n",
    "\n",
    "            for (impute_strategy, impute_param) in impute_params:\n",
    "                # print(\"========== Imputation strategy %s ==========\" % impute_strategy)\n",
    "                try:\n",
    "                    X_train_imputed = impute_data(\n",
    "                        X_train_miss, strategy=impute_strategy, **impute_param\n",
    "                    )\n",
    "                    y_train_imputed = y_train.loc[X_train_imputed.index]\n",
    "\n",
    "                    # print(\"Retrain model on imputed data\")\n",
    "                    model.fit(X_train_imputed, y_train_imputed)\n",
    "                    # make use of metric\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    metric_score = metric(y_test, y_pred)\n",
    "                except ValueError as e:\n",
    "                    # print(\n",
    "                    #     \"Could not train model or compute accuracy. Continue to next training instance.\"\n",
    "                    # )\n",
    "                    # print(e)\n",
    "                    continue\n",
    "                # print(\"Metric score: %s\" % metric_score)\n",
    "\n",
    "                results[\"exp_rep\"].append(rep)\n",
    "                results[\"missing_frac\"].append(missing_frac)\n",
    "                results[\"strategy\"].append(impute_strategy)\n",
    "                results[\"metric_score\"].append(metric_score)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rhp23hAMZaDp"
   },
   "source": [
    "Some utility function for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmlVZ5GJZaDq",
    "pycharm": {
     "name": "#%%  \n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_col_vs_metric_score(\n",
    "    results_df,\n",
    "    feature_col=\"missing_frac\",\n",
    "    metric_score=\"metric_score\",\n",
    "    group_col=\"strategy\",\n",
    "):\n",
    "    \"\"\"\n",
    "    How does each model perform based on a single feature (averaged across other relevant features) wrt a metric score\n",
    "    :param group_col:\n",
    "    :param results_df:\n",
    "    :param feature_col:\n",
    "    :param metric_score:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return sns.lineplot(\n",
    "        x=feature_col,\n",
    "        y=metric_score,\n",
    "        hue=group_col,\n",
    "        style=group_col,\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "        data=results_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wr1EUEaZaDv",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Experiment no. 1: Wine dataset with simple linear regression (MCAR & MAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_wine()\n",
    "X = standardise(X)\n",
    "print(\"Design matrix\")\n",
    "print(X.shape)\n",
    "print(X.head())\n",
    "print(\"\\nTarget\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9JFXzd8qZaDx",
    "outputId": "8884bbe0-c609-4380-daa0-5bbfc1981a0b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "metric = metrics.mean_squared_error\n",
    "missing_fracs = np.linspace(0.0, 0.9, 10)\n",
    "\n",
    "wine_results_mcar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    impute_params = [\n",
    "            (\"complete_case\", {}),\n",
    "            (\"mean\", {}),\n",
    "            (\"median\", {}),\n",
    "            # (\"most_frequent\", {}),\n",
    "            # (\"zero\", {}),\n",
    "            (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "            (\"mice\", {}),\n",
    "        ],\n",
    "    missingness=\"mcar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "metric = metrics.mean_squared_error\n",
    "missing_fracs = np.linspace(0.0, 0.9, 10)\n",
    "\n",
    "wine_results_mar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    impute_params = [\n",
    "            (\"complete_case\", {}),\n",
    "            (\"mean\", {}),\n",
    "            (\"median\", {}),\n",
    "            # (\"most_frequent\", {}),\n",
    "            # (\"zero\", {}),\n",
    "            (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "            (\"mice\", {}),\n",
    "        ],\n",
    "    missingness=\"mar\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(wine_results_mcar)\n",
    "# feature_col_vs_metric_score(wine_results_mcar[~wine_results_mcar['strategy'].isin([\"complete_case\"])])\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(wine_results_mar)\n",
    "# feature_col_vs_metric_score(wine_results_mar[~wine_results_mar['strategy'].isin([\"complete_case\", \"zero\"])])\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment no. 2: Breast cancer dataset with random forest (MCAR & MAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data(\"breast_cancer\")\n",
    "X = standardise(X)\n",
    "print(\"Design matrix\")\n",
    "X = X.iloc[:, :10]\n",
    "print(X.shape)\n",
    "print(X.head())\n",
    "print(\"\\nTarget\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=40)\n",
    "# model = KNeighborsClassifier()\n",
    "metric = metrics.accuracy_score\n",
    "missing_fracs = np.linspace(0.0, 0.9, 10)\n",
    "\n",
    "breast_cancer_results_rf_mcar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    impute_params = [\n",
    "            (\"complete_case\", {}),\n",
    "            (\"mean\", {}),\n",
    "            (\"median\", {}),\n",
    "            # (\"most_frequent\", {}),\n",
    "            # (\"zero\", {}),\n",
    "            (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "            (\"mice\", {}),\n",
    "        ],\n",
    "    missingness=\"mcar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=40)\n",
    "# model = KNeighborsClassifier()\n",
    "metric = metrics.accuracy_score\n",
    "missing_fracs = np.linspace(0.0, 0.9, 10)\n",
    "\n",
    "breast_cancer_results_rf_mar = experiment(\n",
    "    X,\n",
    "    y,\n",
    "    model=model,\n",
    "    metric=metric,\n",
    "    reps=1,\n",
    "    missing_fracs=missing_fracs,\n",
    "    impute_params = [\n",
    "            (\"complete_case\", {}),\n",
    "            (\"mean\", {}),\n",
    "            (\"median\", {}),\n",
    "            # (\"most_frequent\", {}),\n",
    "            # (\"zero\", {}),\n",
    "            (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "            (\"mice\", {}),\n",
    "        ],\n",
    "    missingness=\"mar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(breast_cancer_results_rf_mcar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(breast_cancer_results_rf_mar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment no. 3: Census dataset with random forest (MCAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_census()\n",
    "\n",
    "print(\"Design matrix\")\n",
    "print(X.shape)\n",
    "print(X.head())\n",
    "print(\"\\nTarget\")\n",
    "print(y.head())\n",
    "\n",
    "# X = X.sample(n=10000)\n",
    "# y = y.loc[X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[[\"age\", \"education\", \"occupation\", \"hours_per_week\"]]\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"========== After reduction ==========\")\n",
    "print(\"Design matrix\")\n",
    "print(X.shape)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = X.columns.to_list()\n",
    "# non_cat_names = [\"age\", \"fnlwgt\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",]\n",
    "# cat_names = list(set(cols) - set(non_cat_names))\n",
    "# cat_col_idx = [cols.index(cat_name) for cat_name in cat_names]\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=100)\n",
    "# metric = metrics.accuracy_score\n",
    "# missing_fracs = np.linspace(0.0, 0.9, 5)\n",
    "\n",
    "# census_results_mcar = experiment(\n",
    "#     X,\n",
    "#     y,\n",
    "#     model=model,\n",
    "#     metric=metric,\n",
    "#     reps=1,\n",
    "#     missing_fracs=missing_fracs,\n",
    "#     impute_params = [\n",
    "#             (\"complete_case\", {}),\n",
    "#             # (\"mean\", {}),\n",
    "#             # (\"median\", {}),\n",
    "#             (\"most_frequent\", {}),\n",
    "#             # (\"zero\", {}),\n",
    "#             # (\"knn\", {\"k\": 3, \"verbose\": False}),\n",
    "#             (\"mice\", {}),\n",
    "#             (\"miss-forest\", {\"n_estimators\": 100, \"cat_vars\": cat_col_idx}),\n",
    "#         ],\n",
    "#     missingness=\"mcar\",\n",
    "# )\n",
    "census_results_mcar = pd.read_csv(\"census_mcar_results.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_col_vs_metric_score(census_results_mcar)\n",
    "plt.gca().set_ylim(bottom=0)\n",
    "plt.xticks(missing_fracs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
